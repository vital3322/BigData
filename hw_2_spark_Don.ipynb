{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 2 Титаник (Дон)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "import py4j\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "from pyspark.mllib.tree import RandomForest, RandomForestModel\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "\n",
    "pd.set_option('display.width', 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### создаем спарк контест и считываем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = (SparkConf().setMaster(\"local[8]\")\n",
    "        .setAppName(\"ML demo\")\n",
    "        .set(\"spark.executor.memory\", \"1g\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlcontext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlcontext.read.format(\n",
    "     'com.databricks.spark.csv').options(\n",
    "     header='true').load('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### отбор фич"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) титул"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(name):\n",
    "    if pd.isnull(name):\n",
    "        return \"Null\"\n",
    "\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1).lower()\n",
    "    else:\n",
    "        return \"None\"\n",
    "udf_get_title = udf(get_title, StringType())\n",
    "df2 = df.withColumn('title', udf_get_title(df['Name']))\n",
    "\n",
    "stringIndexer = StringIndexer(inputCol=\"title\", outputCol=\"titleIndex\")\n",
    "model = stringIndexer.fit(df2)\n",
    "indexed = model.transform(df2)\n",
    "encoder = OneHotEncoder(inputCol=\"titleIndex\", outputCol=\"titleVec\")\n",
    "df3 = encoder.transform(indexed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) наличие семьи(больше 3ех родственников на борту)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_family(name, parch, sibsp):\n",
    "    last_name = name.split(\",\")[0]\n",
    "    if last_name:\n",
    "        family_size = 1 + int(parch) + int(sibsp)\n",
    "        if family_size > 3:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "udf_get_family = udf(get_family, StringType())\n",
    "df4 = df3.withColumn('family', udf_get_family(df3['Name'], df3['Parch'], df3['SibSp']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Количество родственников на борту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relatives(name, parch, sibsp):\n",
    "    last_name = name.split(\",\")[0]\n",
    "    if last_name:\n",
    "        family_size = 1 + int(parch) + int(sibsp)\n",
    "        return family_size\n",
    "    else:\n",
    "        return 0\n",
    "udf_get_relatives = udf(get_relatives, StringType())\n",
    "df5 = df4.withColumn('relatives', udf_get_relatives(df3['Name'], df4['Parch'], df4['SibSp']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Человек-одиночка?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single(name, parch, sibsp):\n",
    "    last_name = name.split(\",\")[0]\n",
    "    if last_name:\n",
    "        family_size = 1 + int(parch) + int(sibsp)\n",
    "        if family_size == 0:\n",
    "            return 1\n",
    "        else: \n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "udf_get_single = udf(get_single, StringType())\n",
    "df6 = df5.withColumn('single', udf_get_single(df5['Name'], df5['Parch'], df5['SibSp']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) разобьем возраст по категориям с шагом 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_category(x):\n",
    "    try:\n",
    "        x = int(x)\n",
    "    except:\n",
    "        return -1\n",
    "    return x // 5\n",
    "udf_age_category = udf(age_category, IntegerType())\n",
    "df7 = df6.withColumn('age_category', udf_age_category(df6['Age']))\n",
    "stringIndexer = StringIndexer(inputCol=\"age_category\", outputCol=\"age_categoryIndex\")\n",
    "model = stringIndexer.fit(df7)\n",
    "indexed = model.transform(df7)\n",
    "encoder = OneHotEncoder(inputCol=\"age_categoryIndex\", outputCol=\"age_categoryVec\")\n",
    "df8 = encoder.transform(indexed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### заполнение пропусков поля Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Embarked_transform(x):\n",
    "    if x != None:\n",
    "        return x\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "my_udf =udf(Embarked_transform, StringType())\n",
    "df9 = df8.withColumn('Embarked', my_udf(df8['Embarked']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### создание фичей из поля Embarked - EmbarkedIndex, EmbarkedVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringIndexer = StringIndexer(inputCol=\"Embarked\", outputCol=\"EmbarkedIndex\")\n",
    "model = stringIndexer.fit(df9)\n",
    "indexed = model.transform(df9)\n",
    "encoder = OneHotEncoder(inputCol=\"EmbarkedIndex\", outputCol=\"EmbarkedVec\")\n",
    "df10 = encoder.transform(indexed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### создания нового датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transf(r):\n",
    "    return LabeledPoint(\n",
    "        int(r.Survived),\n",
    "        [\n",
    "            int(r.Pclass),\n",
    "            r.Sex == 'male',\n",
    "            float(r.Fare),\n",
    "            int(r.SibSp),\n",
    "            int(r.Parch),\n",
    "            parse_age(r.Age),\n",
    "            int(r.family),\n",
    "            int(r.relatives),\n",
    "            int(r.family)\n",
    "        ] + list(r.EmbarkedVec.toArray()) + list(r.titleVec.toArray()) + list(r.age_categoryVec.toArray())   \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df10.rdd.map(transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForest.trainClassifier(train, numClasses=2, categoricalFeaturesInfo={},numTrees=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(model, test):\n",
    "    values = test.map(lambda x: x.features)\n",
    "    yhat = model.predict(values)\n",
    "    y = test.map(lambda x: x.label)\n",
    "    comp = yhat.zip(y)\n",
    "    errors = comp.map(lambda x: np.absolute(x[0] - x[1]))\n",
    "    return 1 - errors.sum() / errors.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84782608695652173"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(rfc, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Конец"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
